# =============================================================================
# LLM Manager Configuration
# =============================================================================

# =============================================================================
# PROVIDER CONFIGURATION
# =============================================================================

# Primary provider (first choice)
# Options: gemini, openai, anthropic, groq, ollama
PRIMARY_PROVIDER=gemini

# Secondary provider (fallback if primary fails)
SECONDARY_PROVIDER=groq

# Local provider URL (for Ollama)
LOCAL_PROVIDER_URL=http://localhost:11434

# Fallback strategy
# Options: ordered (try in order), latency-based (fastest first)
FALLBACK_STRATEGY=ordered

# =============================================================================
# API KEYS
# =============================================================================

# Google Gemini API Key
# Get from: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=your_gemini_api_key_here

# OpenAI API Key
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic Claude API Key
# Get from: https://console.anthropic.com/
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Groq API Key (fast inference)
# Get from: https://console.groq.com/
GROQ_API_KEY=your_groq_api_key_here

# =============================================================================
# MODEL CONFIGURATION
# =============================================================================

# Default models for each provider
GEMINI_MODEL=gemini-1.5-flash
OPENAI_MODEL=gpt-4o-mini
OLLAMA_MODEL=llama3
GROQ_MODEL=llama-3.1-70b-versatile

# =============================================================================
# ADVANCED SETTINGS
# =============================================================================

# Request timeout (seconds)
REQUEST_TIMEOUT=30

# Max retries for 5xx errors
MAX_RETRIES=2

# Default temperature
DEFAULT_TEMPERATURE=0.7

# Max tokens per request
DEFAULT_MAX_TOKENS=2048
